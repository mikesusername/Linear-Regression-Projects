{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Five Assignment 1: Exploring Lasso with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from math import log, sqrt\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "train_df=pd.read_csv(\"wk3_kc_house_train_data.csv\",dtype=dtype_dict)\n",
    "test_df=pd.read_csv(\"wk3_kc_house_test_data.csv\",dtype=dtype_dict)\n",
    "valid_df=pd.read_csv(\"wk3_kc_house_valid_data.csv\",dtype=dtype_dict)\n",
    "\n",
    "#Create new fetures for sales df\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create lasso object with L1 penalty of 5e2\n",
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    "lasso1=Lasso(alpha=5e2,normalize=True).fit(sales[all_features],sales.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss(ytrue,ypredict):\n",
    "    return ((ytrue-ypredict)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Which features have been selected by Lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0.        ,      0.        ,      0.        ,    134.43931396,\n",
       "            0.        ,      0.        ,      0.        ,      0.        ,\n",
       "            0.        ,      0.        ,  24750.00458561,      0.        ,\n",
       "        61749.10309071,      0.        ,      0.        ,     -0.        ,\n",
       "            0.        ])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[134.43931395541435, 24750.004585609502, 61749.103090708129]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lasso1.coef_[lasso1.coef_!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sqft_living', 'view', 'grade']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_coef=list(lasso1.coef_[lasso1.coef_!=0])\n",
    "lasso_features=[all_features[list(lasso1.coef_).index(element)] for element in nonzero_coef]\n",
    "lasso_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Find the optimum L1 penalty for each l1_penalty in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type np.logspace(1, 7, num=13). Use the train, validation, and test sets given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty=np.logspace(1,7,num=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add features to train, valid and test sets\n",
    "\n",
    "#Add to train...\n",
    "train_df['sqft_living_sqrt'] = train_df['sqft_living'].apply(sqrt)\n",
    "train_df['sqft_lot_sqrt'] = train_df['sqft_lot'].apply(sqrt)\n",
    "train_df['bedrooms_square'] = train_df['bedrooms']*train_df['bedrooms']\n",
    "train_df['floors_square'] = train_df['floors']*train_df['floors']\n",
    "\n",
    "#Add to test...\n",
    "test_df['sqft_living_sqrt'] = test_df['sqft_living'].apply(sqrt)\n",
    "test_df['sqft_lot_sqrt'] = test_df['sqft_lot'].apply(sqrt)\n",
    "test_df['bedrooms_square'] = test_df['bedrooms']*test_df['bedrooms']\n",
    "test_df['floors_square'] = test_df['floors']*test_df['floors']\n",
    "\n",
    "#Add to validation...\n",
    "valid_df['sqft_living_sqrt'] = valid_df['sqft_living'].apply(sqrt)\n",
    "valid_df['sqft_lot_sqrt'] = valid_df['sqft_lot'].apply(sqrt)\n",
    "valid_df['bedrooms_square'] = valid_df['bedrooms']*valid_df['bedrooms']\n",
    "valid_df['floors_square'] = valid_df['floors']*valid_df['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train lasso models, find rss on validation set. Let's also determine the non zero coefficients with each \n",
    "#model\n",
    "penalty_rss=[]\n",
    "for penalty in l1_penalty:\n",
    "    model=Lasso(alpha=penalty,normalize=True).fit(train_df[all_features],train_df.price)\n",
    "    error=rss(valid_df.price,model.predict(valid_df[all_features]))\n",
    "    penalty_rss.append((error,penalty,len(model.coef_[model.coef_!=0]),model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(398213327300134.06, 10.0, 14, 6630155.6686283601),\n",
       " (399041900253348.0, 31.622776601683793, 14, 6292803.6955100335),\n",
       " (429791604072558.4, 100.0, 10, 5231990.7247574786),\n",
       " (463739831045119.9, 316.22776601683796, 5, 2612357.881978082),\n",
       " (645898733633803.2, 1000.0, 3, -118305.10802037653),\n",
       " (1222506859427156.8, 3162.2776601683795, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 10000.0, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 31622.776601683792, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 100000.0, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 316227.76601683791, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 1000000.0, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 3162277.6601683795, 0, 542734.95164429874),\n",
       " (1222506859427156.8, 10000000.0, 0, 542734.95164429874)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_rss.sort()\n",
    "penalty_rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the lowest penalty, 10, has the least validation error. This is not surprising. These penalties were quite large, causing some features to not be used. Less features may mean less accuracy. Also, we remember that increasing the penalty can reduce overfitting, thereby increasing accuracy on the validation set, but it also trains the model to minimize the lasso cost function and not the rss.\n",
    "\n",
    "By the time the L1 penalty reaches 1000, all coefficients are zero, except for the intercept, which is non zero in all cases.\n",
    "\n",
    "Let us now choose the model with l1 penalty as the optimum model and check the test rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso10=Lasso(alpha=10,normalize=True).fit(train_df[all_features],train_df.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98467402552698.88"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(test_df.price,lasso10.predict(test_df[all_features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Using the best L1 penalty, how many nonzero weights do you have? Count the number of nonzero coefficients first, and add 1 if the intercept is also nonzero.\n",
    "\n",
    "\n",
    "From above, we see that the L1 penalty of 10 has the best validation score. There are 14 nonzero coefficients and a non zero intercept. Thus, we have a total of 15 non zero coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#More systematically, we can use the following code to count non zero coefficients\n",
    "def coef_counter(model):\n",
    "    return np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_counter(lasso10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them.\n",
    "\n",
    "You are going to implement a simple, two phase procedure to achieve this goal:\n",
    "\n",
    "Explore a large range of ‘l1_penalty’ values to find a narrow region of ‘l1_penalty’ values where models are likely to have the desired number of non-zero weights.\n",
    "    \n",
    "Further explore the narrow region you found to find a good value for ‘l1_penalty’ that achieves the desired sparsity. Here, we will again use a validation set to choose the best value for ‘l1_penalty’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_num_nonzero=[]\n",
    "alpha_search1=np.logspace(1,4,num=20)\n",
    "for penalty in alpha_search1:\n",
    "    model=Lasso(alpha=penalty,normalize=True).fit(train_df[all_features],train_df.price)\n",
    "    alpha_num_nonzero.append((penalty,coef_counter(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10.0, 15),\n",
       " (14.384498882876629, 15),\n",
       " (20.691380811147901, 15),\n",
       " (29.763514416313178, 15),\n",
       " (42.813323987193932, 13),\n",
       " (61.584821106602639, 12),\n",
       " (88.586679041008225, 11),\n",
       " (127.42749857031335, 10),\n",
       " (183.29807108324357, 7),\n",
       " (263.66508987303581, 6),\n",
       " (379.26901907322497, 6),\n",
       " (545.55947811685144, 6),\n",
       " (784.75997035146065, 5),\n",
       " (1128.8378916846884, 3),\n",
       " (1623.776739188721, 3),\n",
       " (2335.7214690901214, 2),\n",
       " (3359.8182862837812, 1),\n",
       " (4832.9302385717519, 1),\n",
       " (6951.9279617756056, 1),\n",
       " (10000.0, 1)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_num_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_coef=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The minimum L1 penalty is the largest alpha that has more nonzeros than desired_alpha.\n",
    "#The maximum L1 penalty is the smallest alpha that has fewer nonzeros than desired_alpha\n",
    "test_list=[tup for tup in alpha_num_nonzero if tup[1]>desired_coef]\n",
    "test_list.sort()\n",
    "l1_penalty_min=test_list[-1][0]   \n",
    "\n",
    "test_list2=[tup for tup in alpha_num_nonzero if tup[1]<desired_coef]\n",
    "test_list2.sort()\n",
    "l1_penalty_max=test_list2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.42749857031335"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.66508987303581"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Search over a range of alpha values between the min and max values found previously. Fit models on the training\n",
    "data and find the rss of the prediction of the validation set. Of the models that have the desired number of coefficients, chose the model with the lowest rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizing_list=[]\n",
    "for penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    model=Lasso(alpha=penalty,normalize=True).fit(train_df[all_features],train_df.price)\n",
    "    RSS=rss(valid_df.price,model.predict(valid_df[all_features]))\n",
    "    optimizing_list.append((RSS,penalty,coef_counter(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_list2=[tup for tup in optimizing_list if tup[2]==7]\n",
    "opt_list2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimum_rss=opt_list2[0][0]\n",
    "optimum_alpha=opt_list2[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum alpha: 156.10909673930755\n",
      "Optimum rss: 440037365263317.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimum alpha: {}\\nOptimum rss: {}\".format(optimum_alpha,optimum_rss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Redefine the model with this alpha\n",
    "optimum_lasso=Lasso(alpha=optimum_alpha,normalize=True).fit(train_df[all_features],train_df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.00000000e+00,  -0.00000000e+00,   1.06108903e+04,\n",
       "         1.63380252e+02,   0.00000000e+00,  -0.00000000e+00,\n",
       "        -0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.06451687e+05,   4.19600436e+04,   0.00000000e+00,\n",
       "         1.16253554e+05,   0.00000000e+00,   0.00000000e+00,\n",
       "        -2.61223488e+03,   0.00000000e+00])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4422190.2791203531"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimum_lasso.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 \n",
    "What features were selected in our optimum lasso model with 7 features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bathrooms\n",
      "sqft_living\n",
      "waterfront\n",
      "view\n",
      "grade\n",
      "yr_built\n"
     ]
    }
   ],
   "source": [
    "for item in optimum_lasso.coef_[optimum_lasso.coef_!=0]:\n",
    "    print(all_features[list(optimum_lasso.coef_).index(item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
