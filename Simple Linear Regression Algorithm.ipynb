{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Algorithm (from scratch)\n",
    "\n",
    "The purpose of this module is to create a simple (two dimensional) linear regression algorithm from scratch. We will first use a numerical method (gradient descent) to minimize our cost function. Then we will find an exact solution by setting the gradient of the cost function to zero.\n",
    "\n",
    "The complete description of the theory and method for the algorithm can be found in the pdf document titled \"Linear Regression.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "Let's create a simple data set of roughly linear data in two dimensions. We will use this set to practice our algorithm with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=list(range(6))\n",
    "y=[1,3,7,13,21,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24c48c7e0b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c443f8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=4.7142857142857144, intercept=-0.6190476190476204, rvalue=0.9801595866926569, pvalue=0.00058655799031968534, stderr=0.47666642880922783)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Line of best fit via scipy\n",
    "scipy.stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Linear Regression (Numerical Method)\n",
    "Given values for intercept and slope (omega not and omega one, respectively), we will use an iterative process to determine new values of these parameters. The process works as follows: given initial values of the parameters, the next set of parameters will be the sum of the old and eta times the negative of the gradient of the residual sum of squares (the quantity we are trying to minimize), where eta is a pre determined step size. \n",
    "\n",
    "Our initial guess for the slope and intercept can be made my finding the equation of the line between the first and last data point. The iteration will stop when the gradient is smaller than a specified value (epsilon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define functions that compute the partial derivatives of the residual sum of squares (evaluated at the given points)\n",
    "def omega_not_prime(yseries,xseries,omega_not,omega_one):\n",
    "    part_sum=yseries-(omega_not+(omega_one*xseries))\n",
    "    return part_sum.sum()\n",
    "\n",
    "def omega_one_prime(yseries,xseries,omega_not,omega_one):\n",
    "    part_sum=xseries*(yseries-(omega_not+(omega_one*xseries)))\n",
    "    return part_sum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs=pd.Series(x)\n",
    "ys=pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The regressor function will take x values, y values, epsilon, eta, and maxitter as inputs. The x and y values must be pandas\n",
    "#series. Epsilon is a positive number and is the convergence criteria. Eta is the iteration step size. maxitter is a positive\n",
    "#integer specifying the maximum number of iterations to perform in the case of non convergence.\n",
    "def regressor(yseries,xseries,epsilon,eta,maxitter):\n",
    "    #Calculate initial slope as the slope between the first and last points\n",
    "    omega_one=(yseries[len(yseries)-1]-yseries[0])/(xseries[len(xseries)-1]-xseries[0])\n",
    "    #Calculate initial intercept using the slople calculated above and the first data point\n",
    "    omega_not=yseries[0]-(omega_one*xseries[0])\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    while True:\n",
    "        i+=1\n",
    "        o_not_p=omega_not_prime(yseries,xseries,omega_not,omega_one)\n",
    "        o_one_p=omega_one_prime(yseries,xseries,omega_not,omega_one)\n",
    "        omega_not=omega_not+(2*eta*o_not_p)\n",
    "        omega_one=omega_one+(2*eta*o_one_p)\n",
    "        if abs(o_not_p)<epsilon and abs(o_one_p)<epsilon:\n",
    "            break\n",
    "        if i>maxitter:\n",
    "            break\n",
    "    rss=((yseries-(omega_one*xseries+omega_not))**2).sum()\n",
    "    print(\"\\n\\nomega_not: {}\\nomega_one: {}\\niterations: {}\\nomega_not prime: {}\\nomega_one prime: {}\\nrss: {}\".format(omega_not,omega_one,\n",
    "                                                                                                  i,o_not_p,o_one_p,rss))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "omega_not: -0.619042299085834\n",
      "omega_one: 4.714284215062019\n",
      "iterations: 350\n",
      "omega_not prime: -9.778114995029341e-06\n",
      "omega_one prime: 2.7555802804002383e-06\n",
      "rss: 15.904761904816064\n"
     ]
    }
   ],
   "source": [
    "regressor(ys,xs,0.00001,.01,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Linear Regression (Setting Gradient of RSS to Zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting the gradient of the rss to zero and solving for omega_one and omega_not, we arrive at the following functions\n",
    "def omega_one_calculator(xseries,yseries):\n",
    "    numerator=(xseries*yseries).sum()-(yseries.sum()*xseries.sum()/len(xseries))\n",
    "    denominator=(xseries*xseries).sum()-((xseries.sum()**2))/len(xseries)\n",
    "    return numerator/denominator\n",
    "\n",
    "def omega_not_calculator(xseries,yseries):\n",
    "    return (yseries.sum()/len(xseries))-(omega_one_calculator(xseries,yseries)*xseries.sum()/len(xseries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega_one: 4.714285714285714\n",
      "omega_not: -0.6190476190476204\n"
     ]
    }
   ],
   "source": [
    "#Calculate the parameters for the series xs and ys\n",
    "print(\"omega_one: {}\\nomega_not: {}\".format(omega_one_calculator(xs,ys),omega_not_calculator(xs,ys)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
